1- Create User with permissions (EBS, EFS):

create user with permissions ("AmazonEBSCSIDriverPolicy", "AmazonElasticFileSystemFullAccess")


üîê 2. Create an AWS Access Key and Store it as a Kubernetes Secret
Step-by-step:

In the AWS Console, go to IAM > Users

Choose your IAM user, then click Security credentials

Click Create access key, and copy both the Access Key ID and Secret Access Key
Then, apply it on your Kubernetes master node:

kubectl create secret generic reda-project \
  --namespace kube-system \
  --from-literal=key_id=AKI************ \
  --from-literal=access_key=HS***************

#üí° This securely stores your AWS credentials as a secret inside Kubernetes, which can be used by EBS/EFS CSI drivers or other cloud-integrated components.


3- create role and Add permissions (EBS, EFS):
create role and Add permissions "AmazonEBSCSIDriverPolicy" and ...

---
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "elasticfilesystem:DescribeAccessPoints",
                "elasticfilesystem:DescribeFileSystems",
                "elasticfilesystem:DescribeMountTargets",
                "ec2:DescribeAvailabilityZones"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticfilesystem:CreateAccessPoint"
            ],
            "Resource": "*",
            "Condition": {
                "StringLike": {
                    "aws:RequestTag/efs.csi.aws.com/cluster": "true"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": [
                "elasticfilesystem:TagResource"
            ],
            "Resource": "*",
            "Condition": {
                "StringLike": {
                    "aws:ResourceTag/efs.csi.aws.com/cluster": "true"
                }
            }
        },
        {
            "Effect": "Allow",
            "Action": "elasticfilesystem:DeleteAccessPoint",
            "Resource": "*",
            "Condition": {
                "StringEquals": {
                    "aws:ResourceTag/efs.csi.aws.com/cluster": "true"
                }
            }
        }
    ]
}



Instal CSI driver:
# FOR EBS

ubuntu@master:~$ kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.14"
--
ubuntu@master:~$ kubectl get csidriver
NAME              ATTACHREQUIRED   PODINFOONMOUNT   STORAGECAPACITY   TOKENREQUESTS   REQUIRESREPUBLISH   MODES        AGE
ebs.csi.aws.com   true             false            false             <unset>         false               Persistent   50m

#FOR EFS
ubuntu@master:~$ kubectl apply -k "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.5"

NAME              ATTACHREQUIRED   PODINFOONMOUNT   STORAGECAPACITY   TOKENREQUESTS   REQUIRESREPUBLISH   MODES        AGE
ebs.csi.aws.com   true             false            false             <unset>         false               Persistent   50m
efs.csi.aws.com   false            false            false             <unset>         false               Persistent   48m


# MySQL
vim secret.yaml
---
apiVersion: v1 
kind: Secret 
metadata:
  name: mysql-pass
type: Opaque 
data:
  password: bXlwYXNzd29yZHNxbA==
---
# Storage Class
vim mysql-sc.yaml
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: mysql-sc
provisioner: ebs.csi.aws.com 
volumeBindingMode: WaitForFirstConsumer
---
# Create Persistent Volume Claim = PVC

vim mysql-pvc.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
spec:
  accessModes: 
    - ReadWriteOnce
  storageClassName: mysql-sc  # you have to use the same name as the storage class you created before go back to the storage class file
  resources:
    requests:
      storage: 5Gi
---
# Create MySQL Deployment

vim mysql-deploy.yaml
---
apiVersion: apps/v1 
kind: Deployment 
metadata:
  name: mysql-app
spec:
  selector:
    matchLabels:          # These MatchLabels are used by the deployment to select the right pods. What ever you write here should be the same as the labels in the pod template
      app: wordpress
      tier: mysql
  template:
    metadata:
      labels:              # This is used to label the pods created by the deployment. These labels must match the selector above so the deployment can manage the correct pods
        app: wordpress
        tier: mysql
    spec:
      containers:
        - name: mysql
          image: mysql:5.6
          env: 
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:           # Gets the value from a Kubernetes Secret
                secretKeyRef:       
                  name: mysql-pass  #The name of the secret that stores the MySQL root password. Make sure it matches the name of the secret you created earlier. go back to the secret file and check the name.
                  key: password     # The key inside the secret that contains the password. Make sure it matches the key used when you created the secret (e.g., password).
          ports:
            - containerPort: 3306
          volumeMounts:
            - name: mysql-storage
              mountPath: /var/lib/mysql  # The path inside the container where MySQL stores its data.
      volumes:
        - name: mysql-storage     # This is the name of the volume that will be mounted to the MySQL container.
          persistentVolumeClaim:
            claimName: mysql-pvc  # The name of the PersistentVolumeClaim that you created earlier. This links the deployment to the storage.
---

# affect the deployment
kubectl apply -f mysql-deploy.yaml
# Check the status of the deployment and pods after that go check in AWS if the EBS volume is created in the Console
---
# Create a Service for MySQL type ClusterIP
vim mysql-svc.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: mysql-svc
spec:
  selector:       # This selector matches the labels of the pods created by the MySQL deployment
    app: wordpress # Make sure this matches the labels in the deployment
    tier: mysql     # Make sure this matches the labels in the deployment
  ports:
    - port: 3306 # The port on which the service will be exposed.
---
kubectl apply -f mysql-svc.yaml
# Check the status of the service
kubectl get svc
# You should see the service created with the ClusterIP type and the port 3306 exposed
# Now you finally have a MySQL deployment running with persistent storage using EBS in AWS.
--------

# WordPress
# Step 2 - Deploy WordPress Application
# Create a Storage Class for wordpress using EFS because WordPress needs to store files like themes, plugins, and uploads, which can be shared across multiple pods. (([EFS: ReadWriteMany])).
vim wordpress-sc.yaml
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: efs-sc
provisioner: efs.csi.aws.com
---
kubectl apply -f wordpress-sc.yaml
kubectl get sc 
# You should see the storage class created with the name efs-sc
# Now go create a efs file system in AWS EFS Console and get the file system ID.
# you should create access point for the EFS file system and get the access point ID, Make sure when you create the access point you set the root directory to /wordpress and set the permissions to 777.
# Make sure you have open the security group for the EFS file system to allow inbound traffic from the worker nodes on port 2049 (NFS) and msut apply in same availability zone as the worker nodes go to Amazon EFS >File systems > Network > Manage security groups.

# Create Persistent Volume = PV
vim wordpress-pv.yaml
---

apiVersion: v1 
kind: PersistentVolume
metadata:
  name: wordpress-efs-pv
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: efs-sc   # Here, specify the name of the StorageClass you created earlier (efs-sc). This links the PersistentVolume to the correct StorageClass.
  csi:
    driver: efs.csi.aws.com # Here, specify the CSI driver name, which should match the StorageClass provisioner (e.g., efs.csi.aws.com).
    volumeHandle: fs-01454ca8b588f2d41::fsap-0fd51eb91e39a8083  # volumeHandle is the unique identifier for your EFS file system and access point.Make sure to use your actual EFS FileSystem ID and Access Point ID in this format:<FileSystemID>::<AccessPointID>
---
kubectl apply -f wordpress-pv.yaml
kubectl get pv
# You should see the PV with status "Available". This means it's ready.
# In the next step, we'll create a PVC that matches the storageClassName, accessModes, and size.
# Once the PVC is created, it will automatically bind to this PV.
# Create the PersistentVolumeClaim (PVC) YAML file

vim wordpress-pvc.yaml
---
apiVersion: v1 
kind: PersistentVolumeClaim  # Declare this resource as a PVC
metadata:
  name: wordpress-efs-pvc    # Name of the PVC
spec:
  accessModes:
    - ReadWriteMany          # Must match the PV's accessModes
  storageClassName: efs-sc   # Must match the PV's storageClassName
  resources: 
    requests:
      storage: 5Gi           # Must be equal to or less than the PV's storage
---
kubectl apply -f wordpress-pvc.yaml
kubectl get pvc # After creating the PVC, run kubectl get pvc and kubectl get pv. Both should show status Bound, meaning the PVC is successfully linked to the PersistentVolume and ready to use.
kubectl get pv 


# MySQL Deployment already exists with its own EBS storage and secret for credentials
# WordPress Deployment is separate and connects to MySQL only via:
#   - mysql-service (ClusterIP service exposing MySQL)
#   - mysql-secret (Kubernetes secret holding DB credentials)
# WordPress does NOT reference or link directly to the MySQL deployment resources
# WordPress storage is backed by EFS via its own PersistentVolumeClaim (PVC)
# This separation:
#   - Uses EBS for MySQL block storage (ReadWriteOnce)
#   - Uses EFS for WordPress shared storage (ReadWriteMany)
#
# This design allows WordPress to store files on scalable, shared EFS storage
# while connecting securely to MySQL through the service and secret.
---
# Creaet Deployment manifest for WordPress 
vim wordpress-app.yaml

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wordpress               # Deployment name for WordPress app
spec:
  selector:
    matchLabels:
      app: wordpress            # Select pods with label app=wordpress
      tier: frontend            # Select pods with label tier=frontend
  template:
    metadata:
      labels:
        app: wordpress          # Pod label app=wordpress
        tier: frontend          # Pod label tier=frontend
    spec:
      containers:
        - name: wordpress
          image: wordpress:php7.1-apache   # WordPress image with PHP 7.1 Apache
          env:
            - name: WORDPRESS_DB_HOST
              value: mysql-svc                 # Reference to MySQL service name
            - name: WORDPRESS_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-pass             # Kubernetes secret name for DB password
                  key: password                # Key inside the secret holding the password
          ports:
            - containerPort: 80                 # Container port exposing HTTP
          volumeMounts:
            - mountPath: /var/www/html          # WordPress persistent storage path
              name: wordpress-storage           # Reference to volume defined below
      volumes:
        - name: wordpress-storage
          persistentVolumeClaim:
            claimName: wordpress-efs-pvc        # PVC name that uses EFS StorageClass

# Note:
# - Make sure the PVC 'wordpress-efs-pvc' exists and uses the EFS StorageClass
# - The secret 'mysql-pass' should contain the MySQL password under the 'password' key
# - Service 'mysql-svc' should expose your MySQL deployment internally
----# We scaled the WordPress deployment from 1 to 2 replicas using:
Run this command > kubectl scale deploy wordpress --replicas=2
#
# After scaling:
# - The deployment shows 2 desired pods (replicas) and both are AVAILABLE and READY.
# - We observe the pods status using:
#     kubectl get pods -o wide
#
# Pod details:
# - One WordPress pod is running on node1.
# - Another WordPress pod is running on node2.
# - Both pods have IP addresses assigned and are in Running state.
# - The MySQL pod remains running on node2.
#
# This demonstrates:
# - Successful scaling of WordPress deployment.
# - Kubernetes scheduling pods across different nodes for load balancing.
# - Pods transitioning through ContainerCreating to Running status.
----
SVC-WORD
# We want to access the WordPress website externally.
# To do this, we create a Kubernetes Service of type LoadBalancer.
# This exposes WordPress outside the cluster with a stable IP or DNS.
#
# The LoadBalancer service on AWS provisions an AWS Load Balancer automatically,
# which routes traffic to WordPress pods inside the cluster.

# Benefits:
# - The Load Balancer distributes incoming traffic across multiple WordPress pods,
#   improving availability and reliability.
# - It provides a single external IP or DNS name to access the application.
# - Supports auto-scaling WordPress pods without changing access points.
#
# This setup ensures high availability and better performance for the WordPress site.

vim wordpress-svc.yaml

---

apiVersion: v1 
kind: Service
metadata: 
  name: wordpress-svc   # Service name to expose WordPress
spec:
  selector:
    app: wordpress      # Select pods with label app=wordpress
    tier: frontend      # Select pods with label tier=frontend
  ports:
    - port: 80          # Service listens on port 80
  type: LoadBalancer    # Creates an AWS Load Balancer to expose service externally
---
kubectl apply -f wordpress-svc.yaml
ubuntu@master:~/WordPressPoject$ kubectl get svc
NAME            TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
kubernetes      ClusterIP      10.96.0.1        <none>        443/TCP        4h55m
mysql-svc       ClusterIP      10.111.158.149   <none>        3306/TCP       141m
wordpress-svc   LoadBalancer   10.109.239.193   <pending>     80:31900/TCP   6s

# Explanation:
# The Service "wordpress-svc" of type LoadBalancer has been created.
# Currently, the EXTERNAL-IP is still <pending>, which means AWS is provisioning the Load Balancer.
#
# Meanwhile, you can access the WordPress website using:
# - The public IP address of any of your cluster‚Äôs nodes
# - The NodePort assigned by the Service (in this case, 31900/TCP)
#
# So, open your browser and go to:
#   http://<public-node-ip>:31900
#
# Once AWS finishes provisioning, the EXTERNAL-IP will show a public IP or DNS name,
# and you can access WordPress directly via that IP on port 80 without using the NodePort.
---
# GO TO AWS CONSOLE. 
# In the Target Group configuration, you need to:
# - Select the protocol (HTTP)
# - Use the Service port (e.g., 31900) or the NodePort assigned by Kubernetes
# - Register your EC2 instances (the nodes running your cluster) as targets
#
# This setup ensures the Load Balancer forwards HTTP traffic on the specified port
# to the correct nodes in your cluster, which then route traffic to the WordPress pods.
#
# Remember:
# - The NodePort (like 31507) is the port the service listens on each node.
# - Your EC2 instances must be registered in the Target Group to receive traffic.
------
# Steps to manually create an AWS Application Load Balancer (ALB) for exposing your Kubernetes service:

# 1. Go to the EC2 console ‚Üí Load Balancers ‚Üí Create Load Balancer ‚Üí Choose "Application Load Balancer".

# 2. Under "Basic Configuration":
#    - Name your ALB.
#    - Set Scheme to "Internet-facing" (to expose it to the public internet).

# 3. Under "Network Mapping":
#    - Select at least two Availability Zones (AZs) for high availability.
#    - Make sure the selected AZs contain **public subnets**.
#    - Ensure your Kubernetes EC2 worker nodes are running in these AZs.

# 4. Under "Security Groups":
#    - Select or create a security group that allows inbound traffic on port 80 (HTTP).
#    - You can also allow HTTPS (port 443) if you plan to add TLS later.

# 5. Under "Listeners and Routing":
#    - Listener: Choose HTTP on port 80.
#    - Action: Forward to the **Target Group** you created earlier.
#    - This Target Group should be configured with:
#        * Protocol: HTTP
#        * Port: NodePort of your Kubernetes service (e.g., 31900)
#        * Target type: instance
#        * Registered targets: your EC2 worker nodes

# 6. Review and Create the Load Balancer:
#    - Once created, the ALB will route external HTTP traffic to your Kubernetes nodes
#      on the NodePort, which then forwards the request to your pods (e.g., WordPress).

# Note:
# - If the ALB stays "unhealthy", double-check:
#     * Health check path (e.g., "/")
#     * Security group rules
#     * That the NodePort is open and reachable on each EC2 node

---# ‚úÖ We successfully completed and deployed the project.
# - The WordPress application is now running on Kubernetes.
# - It is exposed externally through a Service of type LoadBalancer.
# - An AWS Load Balancer is set up and correctly routes traffic to our Kubernetes nodes.
# - WordPress is accessible via the public IP or domain of the Load Balancer.
# - This setup demonstrates high availability, scalability, and external access using Kubernetes and AWS services.
 
------
-# ‚ö†Ô∏è Don't forget to delete the following AWS resources manually after the project:
# - EFS (Elastic File System)
# - ALB (Application Load Balancer)
# This helps prevent unexpected AWS charges for unused resources.
